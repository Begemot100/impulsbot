import os
import time
import re
from flask import session
from openai import OpenAI, OpenAIError
from dotenv import load_dotenv
from .utils.utils import init_db, save_conversation, load_training_text
from .utils.amo_crm import create_lead
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_core.prompts import PromptTemplate

load_dotenv()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–µ–∑–∫–∞ –æ–±—É—á–∞—é—â–µ–≥–æ —Ç–µ–∫—Å—Ç–∞
TRAINING_TEXT = load_training_text()

# –ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω–¥–µ–∫—Å–∞
embedding_model = OpenAIEmbeddings()
db = FAISS.load_local("faiss_index", embedding_model, allow_dangerous_deserialization=True)

def query_with_context(user_question):
    docs = db.similarity_search(user_question, k=3)
    context = "\n\n".join([doc.page_content for doc in docs])
    prompt = f"""
    –ù–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. 
    –ë—É–¥—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º –∫–ª–∏–Ω–∏–∫–∏ —ç—Å—Ç–µ—Ç–∏—á–µ—Å–∫–æ–π –º–µ–¥–∏—Ü–∏–Ω—ã IMPULS.

    –ö–æ–Ω—Ç–µ–∫—Å—Ç:
    {context}

    –í–æ–ø—Ä–æ—Å:
    {user_question}

    –û—Ç–≤–µ—Ç:
    """
    return prompt

SYSTEM_PROMPT = f"""
–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∫–ª–∏–Ω–∏–∫–∏ —ç—Å—Ç–µ—Ç–∏—á–µ—Å–∫–æ–π –º–µ–¥–∏—Ü–∏–Ω—ã IMPULS. –û–±—â–∞–π—Å—è –¥—Ä—É–∂–µ–ª—é–±–Ω–æ, –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –∫–∞–∫ —á–µ–ª–æ–≤–µ–∫, –∏—Å–ø–æ–ª—å–∑—É—è —Å—Ç–∏–ª—å –∏–∑ —Ç–µ–∫—Å—Ç–∞ –Ω–∏–∂–µ. –û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã, –∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä—É–π –∏ —Å–æ–±–∏—Ä–∞–π –∏–º—è, email –∏ —Ç–µ–ª–µ—Ñ–æ–Ω –∫–ª–∏–µ–Ω—Ç–∞. –ò—Å–ø–æ–ª—å–∑—É–π —Å–º–∞–π–ª–∏–∫–∏ üòä, –∏–∑–±–µ–≥–∞–π —à–∞–±–ª–æ–Ω–æ–≤ –∏ –ø–æ–≤—Ç–æ—Ä–æ–≤.

---

{TRAINING_TEXT[:10000]}  # –æ–≥—Ä–∞–Ω–∏—á–∏–º —Ç–µ–∫—Å—Ç –¥–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –¥–ª–∏–Ω—ã

---

–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å:
- –•–æ—á–µ—Ç —É–∑–Ω–∞—Ç—å –æ–± —É—Å–ª—É–≥–∞—Ö ‚Äî –æ–±—ä—è—Å–Ω–∏ –¥–æ—Å—Ç—É–ø–Ω–æ, –¥—Ä—É–∂–µ–ª—é–±–Ω–æ, –ø—Ä–µ–¥–ª–æ–∂–∏ –∑–∞–ø–∏—Å–∞—Ç—å—Å—è
- –£–∫–∞–∑—ã–≤–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É ‚Äî –ø—Ä–µ–¥–ª–æ–∂–∏ —Ä–µ—à–µ–Ω–∏–µ –∏ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é
- –ü–∏—à–µ—Ç –≥—Ä—É–±–æ—Å—Ç–∏ ‚Äî –æ—Ç–≤–µ—Ç—å –≤–µ–∂–ª–∏–≤–æ, –Ω–æ —Å —É–≤–∞–∂–µ–Ω–∏–µ–º –∫ —Å–µ–±–µ
- –£–ø–æ–º–∏–Ω–∞–µ—Ç –±–µ—Ä–µ–º–µ–Ω–Ω–æ—Å—Ç—å ‚Äî –ø–æ–∑–¥—Ä–∞–≤—å –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –≤–µ—Ä–Ω—É—Ç—å—Å—è –ø–æ—Å–ª–µ —Ä–æ–¥–æ–≤
"""

class ImpulsAssistant:
    def __init__(self):
        session.setdefault('conversation_history', [{"role": "system", "content": SYSTEM_PROMPT}])
        session.setdefault('language', None)
        session.setdefault('session_id', str(time.time()))
        session.setdefault('lead_sent', False)

    def save(self):
        session.modified = True

    def process_message(self, msg):
        hist = session['conversation_history']
        hist.append({"role": "user", "content": msg})
        messages_for_gpt = [hist[0]] + hist[-10:]

        try:
            prompt = query_with_context(msg)
            completion = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=messages_for_gpt,
                max_tokens=200,
                temperature=0.3
            )
            usage = completion.usage
            print(
                f"üìä –¢–æ–∫–µ–Ω—ã: prompt={usage.prompt_tokens}, completion={usage.completion_tokens}, total={usage.total_tokens}")
            response = completion.choices[0].message.content.strip()
        except Exception as e:
            print(f"GPT Error: {e}")
            response = "‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—Ç–≤–µ—Ç–∞ –æ—Ç GPT. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ –∏ —Å–æ–∑–¥–∞–Ω–∏—è –ª–∏–¥–∞ –≤ AmoCRM
        if not session.get("lead_sent"):
            email_match = re.search(r'\b[\w.-]+@[\w.-]+\.\w+\b', msg)
            phone_match = re.search(r'\b\d{7,15}\b', msg)
            name_match = re.search(r'\b([\u0410-\u042f\u0430-\u044fA-Z][\u0410-\u042f\u0430-\u044fA-Za-z]+)\b', msg)

            if email_match and phone_match and name_match:
                name = name_match.group()
                email = email_match.group()
                phone = phone_match.group()

                # 1. –°–æ–±–∏—Ä–∞–µ–º –ø–µ—Ä–µ–ø–∏—Å–∫—É
                conversation_log = "\n".join([
                    f"{'üë©‚Äç‚öïÔ∏è –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç' if m['role'] == 'assistant' else 'üßë –ö–ª–∏–µ–Ω—Ç'}: {m['content']}"
                    for m in hist if m['role'] != 'system'
                ])

                # 2. –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–º—É –æ–±—Ä–∞—â–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é GPT
                try:
                    topic_prompt = f"""
                    –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π –¥–∏–∞–ª–æ–≥ —Å –∫–ª–∏–µ–Ω—Ç–æ–º –∏ –æ–ø—Ä–µ–¥–µ–ª–∏ –ö–†–ê–¢–ö–û, –∫–∞–∫–∞—è —É—Å–ª—É–≥–∞ –∏–ª–∏ –∑–∞–ø—Ä–æ—Å –µ–≥–æ –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç, –º–∞–∫—Å–∏–º—É–º 3-5 —Å–ª–æ–≤. 
                    –ü—Ä–∏–º–µ—Ä—ã: "—É–¥–∞–ª–µ–Ω–∏–µ —Ç–∞—Ç—É", "–±–æ—Ç–æ–∫—Å", "–ø–∞–ø–∏–ª–ª–æ–º–∞", "–∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è –∫–æ—Å–º–µ—Ç–æ–ª–æ–≥–∞", "–∑–∞–ø–∏—Å—å –Ω–∞ –ø—Ä–∏—ë–º".

                    –î–∏–∞–ª–æ–≥:
                    {conversation_log}
                    """
                    topic_completion = client.chat.completions.create(
                        model="gpt-3.5-turbo",
                        messages=[
                            {"role": "system",
                             "content": "–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –∫—Ä–∞—Ç–∫–æ —Ñ–æ—Ä–º—É–ª–∏—Ä—É–µ—Ç –ø—Ä–∏—á–∏–Ω—É –æ–±—Ä–∞—â–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞ –ø–æ —Ç–µ–∫—Å—Ç—É."},
                            {"role": "user", "content": topic_prompt}
                        ],
                        max_tokens=20,
                        temperature=0.3
                    )
                    topic = topic_completion.choices[0].message.content.strip()
                except OpenAIError as e:
                    print("‚ö†Ô∏è GPT failed to extract topic:", e)
                    topic = "–ü—Ä–∏—á–∏–Ω–∞ –æ–±—Ä–∞—â–µ–Ω–∏—è –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞"

                # 3. –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–ª—è MESSAGE
                message_text = f"–û–±—Ä–∞—â–µ–Ω–∏–µ –æ—Ç {name}.\n–ü—Ä–∏—á–∏–Ω–∞: {topic}.\n\n–ü–µ—Ä–µ–ø–∏—Å–∫–∞:\n{conversation_log}"

                # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
                file_path = None
                if len(conversation_log.strip()) > 200:
                    os.makedirs("conversations", exist_ok=True)
                    file_name = f"chat_{int(time.time())}.txt"
                    file_path = os.path.join("conversations", file_name)
                    with open(file_path, "w", encoding="utf-8") as f:
                        f.write(conversation_log)

                # 5. –°–æ–∑–¥–∞–Ω–∏–µ —Å–¥–µ–ª–∫–∏ –≤ AmoCRM
                status, result = create_lead(
                    name=name,
                    phone=phone,
                    email=email,
                    message=message_text,
                    file_path=file_path
                )
                print(f"üì© AmoCRM: {status}, {result}")
                session['lead_sent'] = True

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –∏ –æ–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
        hist.append({"role": "assistant", "content": response})
        session['conversation_history'] = hist
        save_conversation(session['session_id'], msg, response)
        self.save()
        return response